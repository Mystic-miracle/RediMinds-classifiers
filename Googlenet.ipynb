{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6fe21f04-cada-49ab-ae34-c0ee64648554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_path = 'Data_Cleaned-20230727T065311Z-001.zip'\n",
    "with zipfile.ZipFile(zip_path,'r') as zip_ref:\n",
    "    zip_ref.extractall('RediMinds/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37aff41-c986-4eb9-8ca7-f6701aec74b1",
   "metadata": {
    "id": "npmDe_CGKoPO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3ca338-17cb-425d-af3c-a04e837dcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0  # Change this to the index of the desired GPU\n",
    "torch.cuda.set_device(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708415da-e338-4d56-ac56-aeee7907514c",
   "metadata": {
    "id": "rGAyI9xdKxTB"
   },
   "outputs": [],
   "source": [
    "DATADIR = \"RediMinds/Data_Cleaned/\"\n",
    "categories = [\"Anaesthesia_machine\",\"baby_incubator\",\"Bone_saws\",\"C_arm\",\"colonoscope\",\"Curved_Mayo_Scissor\",\"difibrillator\",\"Electrocautery_devices\",\"fetal_doppler\",\"forceps\",\"Heart_Lung_Machine\",\"IABP\",\"IMRT\",\"infusion_pump\",\"Laryngoscopes\",\"mayfield_clamp\",\"Needle_Biopsy_Device\",\"phacoemulsification\",\"Radiofrequency_Ablation_Device\",\"Scalpel\",\"Straight_Dissection_Clamp\",\"Straight_Mayo_Scissor\",\"Suction_Machine\",\"ventilator\",\"x_ray\"]\n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc30b3c4-b444-4550-8239-9b1c6e8aaa9b",
   "metadata": {
    "id": "d0mpzTyLK1l2"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, categories, input_size, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = categories\n",
    "        self.input_size = input_size\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        for cat in self.categories:\n",
    "            path = os.path.join(self.data_dir, cat)\n",
    "            class_num = self.categories.index(cat)\n",
    "            for img_name in os.listdir(path):\n",
    "                try:\n",
    "                    img_path = os.path.join(path, img_name)\n",
    "                    img = Image.open(img_path).convert(\"RGB\")\n",
    "                    img = img.resize(self.input_size)\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    self.data.append(img)\n",
    "                    self.labels.append(class_num)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c857aaf8-e5ba-4777-a279-f873058e37e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "4y-YObECLeC2",
    "outputId": "37531a35-eaa5-45a9-a0d6-b7a5e3d683ad",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.CenterCrop(10),\n",
    "    # transforms.RandomRotation(15),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast = 0.25, saturation = 0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.2, 0.2, 0.2))\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(DATADIR, categories, input_size, transform=transform)\n",
    "\n",
    "train_size = int(0.70 * len(dataset))\n",
    "validation_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - validation_size\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size,validation_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aae56db-f0be-48e3-ac59-4442d7c472d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344 716 718\n"
     ]
    }
   ],
   "source": [
    "print(train_size,validation_size,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3074022-6d14-4886-aec0-a04a12b90067",
   "metadata": {
    "id": "HDjJkmtgLjVZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a6f5d-5223-40f8-a565-3a54f764ebe3",
   "metadata": {},
   "source": [
    "class CustomGooglenet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomGooglenet, self).__init__()\n",
    "        googlenet = models.googlenet(pretrained=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "        #googlenet = models.googlenet(pretrained='googlenet')\n",
    "\n",
    "\n",
    "        # Freeze all layers by default\n",
    "        for param in googlenet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # for param in googlenet.inception5a.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        for param in googlenet.inception5b.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.googlenet = nn.Sequential(*list(googlenet.children())[:-1])\n",
    "\n",
    "        self.cnnl = nn.Sequential(\n",
    "            nn.Conv2d(1024,512, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(512,512,kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512,128,kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "            # nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(1024,512, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(512,512,kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            # nn.Conv2d(512,128,kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            # nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        #self.cnnl = nn.Conv2d(512, num_classes, kernel_size=3,padding=1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64,num_classes),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.6),\n",
    "            # nn.Linear(2048,1024),\n",
    "            # nn.ReLU(),\n",
    "            #nn.Linear(1024,1024),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3)\n",
    "            # nn.Linear(4096, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.googlenet(x)\n",
    "        x = x.view(x.size(0), -1,1,1)\n",
    "        x = self.cnnl(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        # x = self.cnnl(x)\n",
    "        # x = torch.flatten(x,1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f9b77bb-e71b-4a76-996c-d6658c956ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGooglenet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomGooglenet, self).__init__()\n",
    "        googlenet = models.googlenet(pretrained=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "        #googlenet = models.googlenet(pretrained='googlenet')\n",
    "\n",
    "\n",
    "        # Freeze all layers by default\n",
    "        for param in googlenet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # for param in googlenet.inception5a.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        for param in googlenet.inception5b.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.googlenet = nn.Sequential(*list(googlenet.children())[:-1])\n",
    "\n",
    "        self.cnnl = nn.Sequential(\n",
    "            nn.Conv2d(1024,4098, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(4098),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Conv2d(4098,4098,kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(4098),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Conv2d(4098,2048,kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "            # nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(1024, 1024, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(1024,512, kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Conv2d(512,512,kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            # nn.Conv2d(512,128,kernel_size = 3, padding = 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            # nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        #self.cnnl = nn.Conv2d(512, num_classes, kernel_size=3,padding=1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            # nn.Linear(4098, 2048),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(2048, 2048),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(2048,num_classes),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.6),\n",
    "            # nn.Linear(2048,1024),\n",
    "            # nn.ReLU(),\n",
    "            #nn.Linear(1024,1024),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3)\n",
    "            # nn.Linear(4096, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.googlenet(x)\n",
    "        x = x.view(x.size(0), -1,1,1)\n",
    "        x = self.cnnl(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        # x = self.cnnl(x)\n",
    "        # x = torch.flatten(x,1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e52875-981f-464a-8597-7d050d33f262",
   "metadata": {},
   "source": [
    "weight_enum = torch.hub.load(\"pytorch/vision\", \"get_model_weights\", name=\"googlenet\")\n",
    "print([weight for weight in weight_enum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "058fe0fb-21af-4792-b8d3-ea515c0f7fe6",
   "metadata": {
    "id": "x03pIT-qMgF1"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_classes = len(categories)\n",
    "model = CustomGooglenet(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size = 20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c3021c0-a29d-4176-8635-58957848a623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googlenet.0.conv.weight: requires_grad=False\n",
      "googlenet.0.bn.weight: requires_grad=False\n",
      "googlenet.0.bn.bias: requires_grad=False\n",
      "googlenet.2.conv.weight: requires_grad=False\n",
      "googlenet.2.bn.weight: requires_grad=False\n",
      "googlenet.2.bn.bias: requires_grad=False\n",
      "googlenet.3.conv.weight: requires_grad=False\n",
      "googlenet.3.bn.weight: requires_grad=False\n",
      "googlenet.3.bn.bias: requires_grad=False\n",
      "googlenet.5.branch1.conv.weight: requires_grad=False\n",
      "googlenet.5.branch1.bn.weight: requires_grad=False\n",
      "googlenet.5.branch1.bn.bias: requires_grad=False\n",
      "googlenet.5.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.5.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.5.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.5.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.5.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.5.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.5.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.5.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.5.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.5.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.5.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.5.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.5.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.5.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.5.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.6.branch1.conv.weight: requires_grad=False\n",
      "googlenet.6.branch1.bn.weight: requires_grad=False\n",
      "googlenet.6.branch1.bn.bias: requires_grad=False\n",
      "googlenet.6.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.6.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.6.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.6.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.6.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.6.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.6.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.6.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.6.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.6.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.6.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.6.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.6.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.6.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.6.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.8.branch1.conv.weight: requires_grad=False\n",
      "googlenet.8.branch1.bn.weight: requires_grad=False\n",
      "googlenet.8.branch1.bn.bias: requires_grad=False\n",
      "googlenet.8.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.8.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.8.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.8.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.8.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.8.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.8.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.8.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.8.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.8.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.8.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.8.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.8.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.8.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.8.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.9.branch1.conv.weight: requires_grad=False\n",
      "googlenet.9.branch1.bn.weight: requires_grad=False\n",
      "googlenet.9.branch1.bn.bias: requires_grad=False\n",
      "googlenet.9.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.9.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.9.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.9.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.9.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.9.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.9.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.9.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.9.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.9.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.9.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.9.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.9.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.9.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.9.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.10.branch1.conv.weight: requires_grad=False\n",
      "googlenet.10.branch1.bn.weight: requires_grad=False\n",
      "googlenet.10.branch1.bn.bias: requires_grad=False\n",
      "googlenet.10.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.10.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.10.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.10.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.10.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.10.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.10.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.10.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.10.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.10.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.10.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.10.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.10.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.10.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.10.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.11.branch1.conv.weight: requires_grad=False\n",
      "googlenet.11.branch1.bn.weight: requires_grad=False\n",
      "googlenet.11.branch1.bn.bias: requires_grad=False\n",
      "googlenet.11.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.11.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.11.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.11.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.11.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.11.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.11.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.11.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.11.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.11.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.11.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.11.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.11.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.11.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.11.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.12.branch1.conv.weight: requires_grad=False\n",
      "googlenet.12.branch1.bn.weight: requires_grad=False\n",
      "googlenet.12.branch1.bn.bias: requires_grad=False\n",
      "googlenet.12.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.12.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.12.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.12.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.12.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.12.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.12.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.12.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.12.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.12.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.12.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.12.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.12.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.12.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.12.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.14.branch1.conv.weight: requires_grad=False\n",
      "googlenet.14.branch1.bn.weight: requires_grad=False\n",
      "googlenet.14.branch1.bn.bias: requires_grad=False\n",
      "googlenet.14.branch2.0.conv.weight: requires_grad=False\n",
      "googlenet.14.branch2.0.bn.weight: requires_grad=False\n",
      "googlenet.14.branch2.0.bn.bias: requires_grad=False\n",
      "googlenet.14.branch2.1.conv.weight: requires_grad=False\n",
      "googlenet.14.branch2.1.bn.weight: requires_grad=False\n",
      "googlenet.14.branch2.1.bn.bias: requires_grad=False\n",
      "googlenet.14.branch3.0.conv.weight: requires_grad=False\n",
      "googlenet.14.branch3.0.bn.weight: requires_grad=False\n",
      "googlenet.14.branch3.0.bn.bias: requires_grad=False\n",
      "googlenet.14.branch3.1.conv.weight: requires_grad=False\n",
      "googlenet.14.branch3.1.bn.weight: requires_grad=False\n",
      "googlenet.14.branch3.1.bn.bias: requires_grad=False\n",
      "googlenet.14.branch4.1.conv.weight: requires_grad=False\n",
      "googlenet.14.branch4.1.bn.weight: requires_grad=False\n",
      "googlenet.14.branch4.1.bn.bias: requires_grad=False\n",
      "googlenet.15.branch1.conv.weight: requires_grad=True\n",
      "googlenet.15.branch1.bn.weight: requires_grad=True\n",
      "googlenet.15.branch1.bn.bias: requires_grad=True\n",
      "googlenet.15.branch2.0.conv.weight: requires_grad=True\n",
      "googlenet.15.branch2.0.bn.weight: requires_grad=True\n",
      "googlenet.15.branch2.0.bn.bias: requires_grad=True\n",
      "googlenet.15.branch2.1.conv.weight: requires_grad=True\n",
      "googlenet.15.branch2.1.bn.weight: requires_grad=True\n",
      "googlenet.15.branch2.1.bn.bias: requires_grad=True\n",
      "googlenet.15.branch3.0.conv.weight: requires_grad=True\n",
      "googlenet.15.branch3.0.bn.weight: requires_grad=True\n",
      "googlenet.15.branch3.0.bn.bias: requires_grad=True\n",
      "googlenet.15.branch3.1.conv.weight: requires_grad=True\n",
      "googlenet.15.branch3.1.bn.weight: requires_grad=True\n",
      "googlenet.15.branch3.1.bn.bias: requires_grad=True\n",
      "googlenet.15.branch4.1.conv.weight: requires_grad=True\n",
      "googlenet.15.branch4.1.bn.weight: requires_grad=True\n",
      "googlenet.15.branch4.1.bn.bias: requires_grad=True\n",
      "cnnl.0.weight: requires_grad=True\n",
      "cnnl.0.bias: requires_grad=True\n",
      "cnnl.1.weight: requires_grad=True\n",
      "cnnl.1.bias: requires_grad=True\n",
      "cnnl.4.weight: requires_grad=True\n",
      "cnnl.4.bias: requires_grad=True\n",
      "cnnl.5.weight: requires_grad=True\n",
      "cnnl.5.bias: requires_grad=True\n",
      "cnnl.8.weight: requires_grad=True\n",
      "cnnl.8.bias: requires_grad=True\n",
      "cnnl.9.weight: requires_grad=True\n",
      "cnnl.9.bias: requires_grad=True\n",
      "head.0.weight: requires_grad=True\n",
      "head.0.bias: requires_grad=True\n",
      "head.1.weight: requires_grad=True\n",
      "head.1.bias: requires_grad=True\n",
      "head.4.weight: requires_grad=True\n",
      "head.4.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6877ce-d740-47ba-bb09-84faf8b50c6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "0eNmu2UJMg7v",
    "outputId": "26814188-ecd3-4f26-bf3f-a7578768454f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 2.8958 | Train Acc: 0.3155 | Val Loss: 3.6114 | Val Acc: 0.5126\n",
      "Epoch 2/50 | Train Loss: 2.0912 | Train Acc: 0.5317 | Val Loss: 3.1635 | Val Acc: 0.6089\n",
      "Epoch 3/50 | Train Loss: 2.1118 | Train Acc: 0.6017 | Val Loss: 1.8981 | Val Acc: 0.6313\n",
      "Epoch 4/50 | Train Loss: 1.8166 | Train Acc: 0.6941 | Val Loss: 0.9847 | Val Acc: 0.7416\n",
      "Epoch 5/50 | Train Loss: 1.4718 | Train Acc: 0.7315 | Val Loss: 0.8797 | Val Acc: 0.7514\n",
      "Epoch 6/50 | Train Loss: 1.5934 | Train Acc: 0.7548 | Val Loss: 1.2831 | Val Acc: 0.7109\n",
      "Epoch 7/50 | Train Loss: 1.5099 | Train Acc: 0.7808 | Val Loss: 1.2590 | Val Acc: 0.7514\n",
      "Epoch 8/50 | Train Loss: 1.4174 | Train Acc: 0.7892 | Val Loss: 1.0361 | Val Acc: 0.7723\n",
      "Epoch 9/50 | Train Loss: 1.2833 | Train Acc: 0.8035 | Val Loss: 0.9758 | Val Acc: 0.7332\n",
      "Epoch 10/50 | Train Loss: 1.0362 | Train Acc: 0.8379 | Val Loss: 1.1197 | Val Acc: 0.7612\n",
      "Epoch 11/50 | Train Loss: 0.9239 | Train Acc: 0.8535 | Val Loss: 1.6213 | Val Acc: 0.7402\n",
      "Epoch 12/50 | Train Loss: 0.9030 | Train Acc: 0.8379 | Val Loss: 1.1778 | Val Acc: 0.7807\n",
      "Epoch 13/50 | Train Loss: 1.0205 | Train Acc: 0.8397 | Val Loss: 2.2220 | Val Acc: 0.7528\n",
      "Epoch 14/50 | Train Loss: 0.7759 | Train Acc: 0.8541 | Val Loss: 1.3140 | Val Acc: 0.7765\n",
      "Epoch 15/50 | Train Loss: 0.6733 | Train Acc: 0.8615 | Val Loss: 1.0020 | Val Acc: 0.7863\n",
      "Epoch 16/50 | Train Loss: 0.5137 | Train Acc: 0.8873 | Val Loss: 0.9419 | Val Acc: 0.8170\n",
      "Epoch 17/50 | Train Loss: 0.4980 | Train Acc: 0.8834 | Val Loss: 1.0431 | Val Acc: 0.7863\n",
      "Epoch 18/50 | Train Loss: 0.4795 | Train Acc: 0.8929 | Val Loss: 0.9487 | Val Acc: 0.7877\n",
      "Epoch 19/50 | Train Loss: 0.5219 | Train Acc: 0.8789 | Val Loss: 1.0457 | Val Acc: 0.7779\n",
      "Epoch 20/50 | Train Loss: 0.4272 | Train Acc: 0.8929 | Val Loss: 0.9019 | Val Acc: 0.8003\n",
      "Epoch 21/50 | Train Loss: 0.4410 | Train Acc: 0.9004 | Val Loss: 0.9109 | Val Acc: 0.7975\n",
      "Epoch 22/50 | Train Loss: 0.3855 | Train Acc: 0.9085 | Val Loss: 0.8206 | Val Acc: 0.8142\n",
      "Epoch 23/50 | Train Loss: 0.2792 | Train Acc: 0.9231 | Val Loss: 0.8808 | Val Acc: 0.8059\n",
      "Epoch 24/50 | Train Loss: 0.3342 | Train Acc: 0.9181 | Val Loss: 0.7800 | Val Acc: 0.8212\n",
      "Epoch 25/50 | Train Loss: 0.2687 | Train Acc: 0.9276 | Val Loss: 0.7497 | Val Acc: 0.8310\n",
      "Epoch 26/50 | Train Loss: 0.2579 | Train Acc: 0.9357 | Val Loss: 0.9892 | Val Acc: 0.8031\n",
      "Epoch 27/50 | Train Loss: 0.2571 | Train Acc: 0.9348 | Val Loss: 0.8910 | Val Acc: 0.8142\n"
     ]
    }
   ],
   "source": [
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, train_corrects = 0.0, 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        labels = torch.squeeze(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_acc = train_corrects / len(train_dataset)\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_corrects = 0.0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    val_loss = val_loss / len(validation_dataset)\n",
    "    val_acc = val_corrects / len(validation_dataset)\n",
    "\n",
    "    val_acc_history.append(val_acc)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    # scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefe14b-8f4f-4961-a290-53e37b4133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, num_epochs+1), train_acc_history, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), val_acc_history, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(1, num_epochs+1), train_loss_history, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), val_loss_history, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377f41d-464d-4458-afdc-7f06f737365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, test_corrects = 0.0, 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "test_acc = test_corrects / len(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022275-bc1c-497a-9785-0a079d5949d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b23ff320-f56f-4cbe-901a-67402a14e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model_torch_googlenet_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "653fbcc6-9ba2-4fa1-a54c-59d1abacca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e64341-dd66-4afc-b4f6-10b2f7fd6bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
